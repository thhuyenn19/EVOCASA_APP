import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from firebase_util import init_firebase, get_all_documents_as_texts

load_dotenv()
init_firebase()

# Táº¡o vectorstore
embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = Chroma(persist_directory="chroma_store", embedding_function=embedding)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 10})  # TÄƒng k lÃªn 10

# Cáº¥u hÃ¬nh LLM vÃ  chain
llm = ChatGoogleGenerativeAI(model="models/gemini-1.5-pro", temperature=0.2)
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key="answer"
)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=retriever,
    memory=memory,
    chain_type="stuff",
    return_source_documents=True,
    output_key="answer",
    combine_docs_chain_kwargs={"prompt": PromptTemplate(
        input_variables=["context", "question"],
        template="""
Báº¡n lÃ  trá»£ lÃ½ bÃ¡n hÃ ng thÃ´ng minh. Dá»±a trÃªn thÃ´ng tin sau: {context}, hÃ£y tráº£ lá»i cÃ¢u há»i: {question} má»™t cÃ¡ch ngáº¯n gá»n vÃ  chÃ­nh xÃ¡c.

- Náº¿u cÃ¢u há»i lÃ  'list category', hÃ£y liá»‡t kÃª táº¥t cáº£ cÃ¡c danh má»¥c (Name) tá»« dá»¯ liá»‡u.
- Náº¿u cÃ¢u há»i lÃ  'list parent category', hÃ£y liá»‡t kÃª táº¥t cáº£ cÃ¡c danh má»¥c cÃ³ ParentCategory lÃ  'None' (lÃ  danh má»¥c cha), bá» qua cÃ¡c danh má»¥c con.
- Sá»­ dá»¥ng Ä‘á»‹nh dáº¡ng:
  - Danh má»¥c 1
  - Danh má»¥c 2
  - ...
- Náº¿u dá»¯ liá»‡u khÃ´ng Ä‘áº§y Ä‘á»§, hÃ£y thÃ´ng bÃ¡o: 'Dá»¯ liá»‡u khÃ´ng Ä‘á»§ Ä‘á»ƒ liá»‡t kÃª Ä‘áº§y Ä‘á»§.'
"""
    )}
)

print("ğŸ’¬ Nháº­p cÃ¢u há»i (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t)")
while True:
    query = input("\nBáº¡n: ")
    if query.strip().lower() == "exit":
        break

    result = qa_chain.invoke({"question": query})
    print(f"\nğŸ¤– Gemini tráº£ lá»i:\n{result['answer']}")
    print(f"\nğŸ“š TÃ i liá»‡u tham chiáº¿u: {result['source_documents']}")