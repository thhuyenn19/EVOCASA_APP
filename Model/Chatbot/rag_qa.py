import os
from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import Chroma  # S·ª≠ d·ª•ng t·∫°m, c·∫ßn c·∫≠p nh·∫≠t sau
from langchain.chains import ConversationalRetrievalChain
from langchain.memory import ConversationBufferMemory
from langchain.prompts import PromptTemplate
from firebase_util import init_firebase, get_all_documents_as_texts
from firebase_admin import firestore

load_dotenv()
init_firebase()

# Kh·ªüi t·∫°o Firestore client
db = firestore.client()

# T·∫°o vectorstore (c·∫£nh b√°o v·ªÅ Chroma, c·∫ßn c√†i langchain-chroma)
embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
vectorstore = Chroma(persist_directory="chroma_store", embedding_function=embedding)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 5})

# L·∫•y t·∫•t c·∫£ danh m·ª•c t·ª´ Firestore, bao g·ªìm ParentCategory
def get_all_categories():
    categories = {}
    try:
        docs = db.collection("Category").stream()
        for doc in docs:
            data = doc.to_dict()
            if data and "Name" in data:
                categories[data["Name"]] = data.get("ParentCategory", "None")
    except Exception as e:
        print(f"‚ùå L·ªói khi l·∫•y danh m·ª•c: {e}")
    # L·ªçc danh m·ª•c cha (ParentCategory l√† None ho·∫∑c "None")
    parent_categories = [name for name, parent in categories.items() if parent is None or parent == "None"]
    return sorted(parent_categories)  # S·∫Øp x·∫øp danh s√°ch

# C·∫•u h√¨nh LLM v√† chain
try:
    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-pro", temperature=0.2)
except ValueError as e:
    print(f"‚ö†Ô∏è M√¥ h√¨nh 'gemini-2.5-pro' kh√¥ng kh·∫£ d·ª•ng, d√πng 'gemini-1.5-pro' thay th·∫ø. L·ªói: {e}")
    llm = ChatGoogleGenerativeAI(model="models/gemini-1.5-pro", temperature=0.2)

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    output_key="answer",
    input_key="question"  # Ch·ªâ ƒë·ªãnh kh√≥a ƒë·∫ßu v√†o ch√≠nh
)

qa_chain = ConversationalRetrievalChain.from_llm(
    llm=llm,
    retriever=retriever,
    memory=memory,
    chain_type="stuff",
    return_source_documents=True,
    output_key="answer",
    combine_docs_chain_kwargs={"prompt": PromptTemplate(
        input_variables=["context", "question", "all_categories"],
        template="""
You are an intelligent sales assistant for EvoCasa. Based on the information from the vectorstore: {context} and all categories: {all_categories}, please answer the question: {question} in English, concisely and accurately.

- If the question is 'list category name', 'all category name', or 'give me list category name', list ALL unique category names from {all_categories} in a single list, ignoring the context.
- If the question is 'list parent category', list ONLY the category names from {all_categories}, which are the parent categories (those with no parent category), in a single list, ignoring the context.
- If the question matches any FAQ questions (Question) from the CSV, provide the corresponding Answer in English and use only the most relevant FAQ document.
- If no answer is found, suggest: 'Please contact support via email support@evocasa.com or hotline 1800-XXX-XXX.'
- Use the format:
  - Info 1
  - Info 2
  - ...
"""
    )}
)

print("üí¨ Enter your question (type 'exit' to quit)")
while True:
    query = input("\nYou: ")
    if query.strip().lower() == "exit":
        break

    # L·∫•y t·∫•t c·∫£ danh m·ª•c tr∆∞·ªõc khi invoke
    all_categories = get_all_categories()
    if not all_categories:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y danh m·ª•c n√†o t·ª´ Firestore.")
    # Truy·ªÅn question l√†m input ch√≠nh, all_categories l√†m tham s·ªë b·ªï sung
    result = qa_chain.invoke({"question": query, "all_categories": "\n- ".join(all_categories) if all_categories else "No categories found"})
    print(f"\nü§ñ Gemini answers:\n{result['answer']}")
    print(f"\nüìö Reference documents: {result['source_documents']}")